# -*- coding: utf-8 -*-
"""solubilityLog_ml.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1q9o4AuU59ieL99eCKhgR9hz57Jn5qwPV

# Load data
"""

import pandas as pd

df = pd.read_csv('https://raw.githubusercontent.com/dataprofessor/data/master/delaney_solubility_with_descriptors.csv')

df

"""# Data Preparation

## Data Separation as x and y
"""

y = df['logS']

y

x = df.drop('logS', axis= 1)

x

"""## Split Data"""

from sklearn.model_selection import train_test_split

x_train, x_test, y_train, y_test = train_test_split(x, y, test_size= 0.2, random_state= 100)

x_train

x_test

"""# Model building

## Linear Regression

### Train the model
"""

from sklearn.linear_model import LinearRegression

lr = LinearRegression()

lr.fit(x_train, y_train)

"""### Apply the model to predict"""

y_lr_train_pred = lr.predict(x_train)

y_lr_train_pred

y_lr_test_pred = lr.predict(x_test)

y_lr_test_pred

"""### Evaluate the model performance"""

from sklearn.metrics import mean_squared_error, r2_score

lr_train_mse = mean_squared_error(y_train, y_lr_train_pred)

lr_train_r2 = r2_score(y_train, y_lr_train_pred)

lr_test_mse = mean_squared_error(y_test, y_lr_test_pred)

lr_test_r2 = r2_score(y_test, y_lr_test_pred)

print('LR MSE (Train):', lr_train_mse)
print('LR R2 (Train):', lr_train_r2)
print('LR MSE (Test):', lr_test_mse)
print('LR R2 (Test):', lr_test_r2)

lr_results = pd.DataFrame(['Linear Regression', lr_train_mse, lr_train_r2, lr_test_mse, lr_test_r2]).transpose()

lr_results

lr_results.columns = [ 'Prediction Method', 'Train MSE', 'Train R2', 'Test MSE', 'Test R2']

lr_results

"""## Random Forest

### Train the model
"""

from sklearn.ensemble import RandomForestRegressor

rf = RandomForestRegressor(max_depth= 2, random_state= 100)

rf.fit(x_train, y_train)

"""### Apply the model to predict"""

y_rf_train_predict = rf.predict(x_train)

y_rf_test_predict = rf.predict(x_test)

"""### Evaluate the model performance"""

from sklearn.metrics import mean_squared_error, r2_score

rf_train_mse = mean_squared_error(y_train, y_rf_train_predict)

rf_train_r2 = r2_score(y_train, y_rf_train_predict)

rf_test_mse = mean_squared_error(y_test, y_rf_test_predict)

rf_test_r2 = r2_score(y_test, y_rf_test_predict)

rf_results = pd.DataFrame(['Random Forest', rf_train_mse, rf_train_r2, rf_test_mse, rf_test_r2]).transpose()

rf_results

rf_results.columns = ['Prediction Method', 'Train MSE', 'Train R2', 'Test MSE', 'Test R2']

rf_results

"""## Gaussian Process Regression (GPR)

### Train the model
"""

from sklearn.gaussian_process import GaussianProcessRegressor

gpr = GaussianProcessRegressor()

gpr.fit(x_train, y_train)

"""### Apply the model to predict"""

y_gpr_train_predict = gpr.predict(x_train)

y_gpr_test_predict = gpr.predict(x_test)

"""### Evaluate the model"""

from sklearn.metrics import mean_squared_error, r2_score

gpr_train_mse = mean_squared_error(y_train, y_gpr_train_predict)

gpr_train_r2 = r2_score(y_train, y_gpr_train_predict)

gpr_test_mse = mean_squared_error(y_test, y_gpr_test_predict)

gpr_test_r2 = r2_score(y_test, y_gpr_test_predict)

gpr_results = pd.DataFrame(['Gaussian Process Regression (GPR)', gpr_train_mse, gpr_train_r2, gpr_test_mse, gpr_test_r2]).transpose()

gpr_results

gpr_results.columns = ['Prediction Method', 'Train MSE', 'Train R2', 'Test MSE', 'Test R2']

gpr_results

"""## Compare Models"""

df_models = pd.concat([lr_results, rf_results, gpr_results], axis = 0)

df_models

df_models.reset_index(drop= True)

"""# Data Visualization"""

## **For three plots of training data**
# import matplotlib.pyplot as plt
# import numpy as np
# #
# # Sample data for demonstration
# # Replace these with your actual data
# y_train = np.random.rand(100)
# y_lr_train_pred = np.random.rand(100)
# y_rf_train_pred = np.random.rand(100)
# y_gpr_train_pred = np.random.rand(100)
# sigma = np.random.rand(100) * 0.1

# # Create a figure with three subplots
# fig, (plot_lr, plot_rf, plot_gpr) = plt.subplots(3, 1, figsize=(8, 18))

# # Linear Regression plot
# plot_lr.scatter(x=y_train, y=y_lr_train_pred, alpha=0.2, label='Data')
# z_lr = np.polyfit(y_train, y_lr_train_pred, 1)
# p_lr = np.poly1d(z_lr)
# plot_lr.plot(y_train, p_lr(y_train), '#F8766D', label='Fit')
# plot_lr.set_xlabel('Experimental logS')
# plot_lr.set_ylabel('Predicted logS')
# plot_lr.set_title('Linear Regression')
# plot_lr.legend()

# # Random Forest plot
# plot_rf.scatter(x=y_train, y=y_rf_train_pred, alpha=0.2, label='Data')
# z_rf = np.polyfit(y_train, y_rf_train_pred, 1)
# p_rf = np.poly1d(z_rf)
# plot_rf.plot(y_train, p_rf(y_train), '#00BA38', label='Fit')
# plot_rf.set_xlabel('Experimental logS')
# plot_rf.set_ylabel('Predicted logS')
# plot_rf.set_title('Random Forest')
# plot_rf.legend()

# # Gaussian Process Regression plot
# plot_gpr.scatter(x=y_train, y=y_gpr_train_pred, alpha=0.2, label='Data')
# z_gpr = np.polyfit(y_train, y_gpr_train_pred, 1)
# p_gpr = np.poly1d(z_gpr)
# plot_gpr.plot(y_train, p_gpr(y_train), '#619CFF', label='Fit')
# plot_gpr.fill_between(y_train, y_gpr_train_pred - sigma, y_gpr_train_pred + sigma, color='#619CFF', alpha=0.2, label='Confidence interval')
# plot_gpr.set_xlabel('Experimental logS')
# plot_gpr.set_ylabel('Predicted logS')
# plot_gpr.set_title('Gaussian Process Regression')
# plot_gpr.legend()

# # Adjust layout
# plt.tight_layout()
# plt.show()

## **For 1 plot**

# import matplotlib.pyplot as plt

# import numpy as np

# plt.figure(figsize=(5,5))

# plt.scatter(x= y_train, y= y_lr_train_pred, alpha= 0.2)

# plt.plot(y_train, p(y_train), '#F8766D')

# plt.xlabel('Experimental logS')

# plt.ylabel('Predicted logS')

# z = np.polyfit(y_train, y_lr_train_pred, 1)

# p = np.poly1d(z)

# **For 6 plots**

import matplotlib.pyplot as plt
import numpy as np

# Sample data for demonstration
# Replace these with your actual data
y_train = np.random.rand(100)
y_lr_train_pred = np.random.rand(100)
y_rf_train_pred = np.random.rand(100)
y_gpr_train_pred = np.random.rand(100)
sigma_train = np.random.rand(100) * 0.1

y_test = np.random.rand(50)
y_lr_test_pred = np.random.rand(50)
y_rf_test_pred = np.random.rand(50)
y_gpr_test_pred = np.random.rand(50)
sigma_test = np.random.rand(50) * 0.1

# Create a figure with six subplots
fig, axs = plt.subplots(3, 2, figsize=(15, 18))

# Linear Regression plot (train)
axs[0, 0].scatter(x=y_train, y=y_lr_train_pred, alpha=0.2, label='Data')
z_lr_train = np.polyfit(y_train, y_lr_train_pred, 1)
p_lr_train = np.poly1d(z_lr_train)
axs[0, 0].plot(y_train, p_lr_train(y_train), '#F8766D', label='Fit')
axs[0, 0].set_xlabel('Experimental logS')
axs[0, 0].set_ylabel('Predicted logS')
axs[0, 0].set_title('Linear Regression (Train)')
axs[0, 0].legend()

# Linear Regression plot (test)
axs[0, 1].scatter(x=y_test, y=y_lr_test_pred, alpha=0.2, label='Data')
z_lr_test = np.polyfit(y_test, y_lr_test_pred, 1)
p_lr_test = np.poly1d(z_lr_test)
axs[0, 1].plot(y_test, p_lr_test(y_test), '#F8766D', label='Fit')
axs[0, 1].set_xlabel('Experimental logS')
axs[0, 1].set_ylabel('Predicted logS')
axs[0, 1].set_title('Linear Regression (Test)')
axs[0, 1].legend()

# Random Forest plot (train)
axs[1, 0].scatter(x=y_train, y=y_rf_train_pred, alpha=0.2, label='Data')
z_rf_train = np.polyfit(y_train, y_rf_train_pred, 1)
p_rf_train = np.poly1d(z_rf_train)
axs[1, 0].plot(y_train, p_rf_train(y_train), '#00BA38', label='Fit')
axs[1, 0].set_xlabel('Experimental logS')
axs[1, 0].set_ylabel('Predicted logS')
axs[1, 0].set_title('Random Forest (Train)')
axs[1, 0].legend()

# Random Forest plot (test)
axs[1, 1].scatter(x=y_test, y=y_rf_test_pred, alpha=0.2, label='Data')
z_rf_test = np.polyfit(y_test, y_rf_test_pred, 1)
p_rf_test = np.poly1d(z_rf_test)
axs[1, 1].plot(y_test, p_rf_test(y_test), '#00BA38', label='Fit')
axs[1, 1].set_xlabel('Experimental logS')
axs[1, 1].set_ylabel('Predicted logS')
axs[1, 1].set_title('Random Forest (Test)')
axs[1, 1].legend()

# Gaussian Process Regression plot (train)
axs[2, 0].scatter(x=y_train, y=y_gpr_train_pred, alpha=0.2, label='Data')
z_gpr_train = np.polyfit(y_train, y_gpr_train_pred, 1)
p_gpr_train = np.poly1d(z_gpr_train)
axs[2, 0].plot(y_train, p_gpr_train(y_train), '#619CFF', label='Fit')
axs[2, 0].fill_between(y_train, y_gpr_train_pred - sigma_train, y_gpr_train_pred + sigma_train, color='#619CFF', alpha=0.2, label='Confidence interval')
axs[2, 0].set_xlabel('Experimental logS')
axs[2, 0].set_ylabel('Predicted logS')
axs[2, 0].set_title('Gaussian Process Regression (Train)')
axs[2, 0].legend()

# Gaussian Process Regression plot (test)
axs[2, 1].scatter(x=y_test, y=y_gpr_test_pred, alpha=0.2, label='Data')
z_gpr_test = np.polyfit(y_test, y_gpr_test_pred, 1)
p_gpr_test = np.poly1d(z_gpr_test)
axs[2, 1].plot(y_test, p_gpr_test(y_test), '#619CFF', label='Fit')
axs[2, 1].fill_between(y_test, y_gpr_test_pred - sigma_test, y_gpr_test_pred + sigma_test, color='#619CFF', alpha=0.2, label='Confidence interval')
axs[2, 1].set_xlabel('Experimental logS')
axs[2, 1].set_ylabel('Predicted logS')
axs[2, 1].set_title('Gaussian Process Regression (Test)')
axs[2, 1].legend()

# Adjust layout
plt.tight_layout()
plt.show()